{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Topic Modeling with gensim\n",
    "We'll try out [Latent Dirichlet Allocation (LDA)](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) in [gensim](http://radimrehurek.com/gensim/index.html) on the [20 Newsgroups dataset](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html) with some simple preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "##### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "# sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Let's retain only a subset of the 20 categories in the original 20 Newsgroups Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "2018-02-28 10:51:28,131 : INFO : Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n",
      "2018-02-28 10:51:28,133 : INFO : Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "# Set categories\n",
    "categories = ['alt.atheism', 'comp.graphics', 'rec.sport.baseball']#, \n",
    "              #'rec.motorcycles', 'sci.space', 'talk.politics.mideast']\n",
    "# Download the training subset of the 20 NG dataset, with headers, footers, quotes removed\n",
    "# Only keep docs from the 6 categories above\n",
    "ng_train = datasets.fetch_20newsgroups(subset='train', categories=categories, \n",
    "                                      remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     Since when does atheism mean trashing other religions?There must be a God\\n     of inbreeding to which you are his only son.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first doc\n",
    "ng_train.data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Document Preprocessing\n",
    "We'll need to generate a term-document matrix of word (token) counts for use in LDA.\n",
    "\n",
    "We'll use `sklearn`'s `CountVectorizer` to generate our term-document matrix of counts. We'll make use of a few parameters to accomplish the following preprocessing of the text documents all within the `CountVectorizer`:\n",
    "* `analyzer=word`: Tokenize by word\n",
    "* `ngram_range=(1,2)`: Keep all 1 and 2-word grams\n",
    "* `stop_words=english`: Remove all English stop words\n",
    "* `token_pattern=\\\\b[a-z][a-z]+\\\\b`: Match all tokens with 2 or more (strictly) alphabet characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='\\\\b[a-z][a-z]+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a CountVectorizer for parsing/counting words\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2),  \n",
    "                                   stop_words='english', token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "count_vectorizer.fit(ng_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the term-document matrix\n",
    "# Transpose it so the terms are the rows\n",
    "counts = count_vectorizer.transform(ng_train.data).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118111, 1661)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "##### Convert to gensim\n",
    "We need to convert our sparse `scipy` matrix to a `gensim`-friendly object called a Corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert sparse matrix of counts to a gensim corpus\n",
    "corpus = matutils.Sparse2Corpus(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "##### Map matrix rows to words (tokens)\n",
    "We need to save a mapping (dict) of row id to word (token) for later use by gensim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "id2word = dict((v, k) for k, v in count_vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118111"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'columbia ibm'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[18000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## LDA\n",
    "At this point we can simply plow ahead in creating an LDA model.  It requires our corpus of word counts, mapping of row ids to words, and the number of topics (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-28 11:10:01,357 : INFO : using symmetric alpha at 0.16666666666666666\n",
      "2018-02-28 11:10:01,358 : INFO : using symmetric eta at 0.16666666666666666\n",
      "2018-02-28 11:10:01,379 : INFO : using serial LDA version on this node\n",
      "2018-02-28 11:10:04,507 : INFO : running online (multi-pass) LDA training, 6 topics, 10 passes over the supplied corpus of 1661 documents, updating model once every 1661 documents, evaluating perplexity every 1661 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2018-02-28 11:10:14,222 : INFO : -14.519 per-word bound, 23478.4 perplexity estimate based on a held-out corpus of 1661 documents with 241616 words\n",
      "2018-02-28 11:10:14,222 : INFO : PROGRESS: pass 0, at document #1661/1661\n",
      "2018-02-28 11:10:16,984 : INFO : topic #0 (0.167): 0.002*\"don\" + 0.001*\"time\" + 0.001*\"graphics\" + 0.001*\"does\" + 0.001*\"like\" + 0.001*\"know\" + 0.001*\"just\" + 0.001*\"good\" + 0.001*\"image\" + 0.001*\"think\"\n",
      "2018-02-28 11:10:16,986 : INFO : topic #5 (0.167): 0.002*\"image\" + 0.002*\"god\" + 0.001*\"year\" + 0.001*\"does\" + 0.001*\"think\" + 0.001*\"good\" + 0.001*\"just\" + 0.001*\"don\" + 0.001*\"like\" + 0.001*\"jpeg\"\n",
      "2018-02-28 11:10:16,990 : INFO : topic #1 (0.167): 0.002*\"don\" + 0.002*\"people\" + 0.002*\"image\" + 0.002*\"think\" + 0.002*\"just\" + 0.001*\"like\" + 0.001*\"edu\" + 0.001*\"god\" + 0.001*\"good\" + 0.001*\"time\"\n",
      "2018-02-28 11:10:16,992 : INFO : topic #4 (0.167): 0.002*\"edu\" + 0.001*\"don\" + 0.001*\"people\" + 0.001*\"image\" + 0.001*\"know\" + 0.001*\"use\" + 0.001*\"time\" + 0.001*\"graphics\" + 0.001*\"just\" + 0.001*\"say\"\n",
      "2018-02-28 11:10:16,995 : INFO : topic #2 (0.167): 0.002*\"like\" + 0.002*\"just\" + 0.002*\"don\" + 0.002*\"know\" + 0.002*\"think\" + 0.002*\"people\" + 0.001*\"graphics\" + 0.001*\"time\" + 0.001*\"edu\" + 0.001*\"god\"\n",
      "2018-02-28 11:10:16,997 : INFO : topic diff=2.145723, rho=1.000000\n",
      "2018-02-28 11:10:21,438 : INFO : -11.979 per-word bound, 4036.5 perplexity estimate based on a held-out corpus of 1661 documents with 241616 words\n",
      "2018-02-28 11:10:21,439 : INFO : PROGRESS: pass 1, at document #1661/1661\n",
      "2018-02-28 11:10:23,192 : INFO : topic #5 (0.167): 0.003*\"jpeg\" + 0.002*\"image\" + 0.002*\"year\" + 0.002*\"does\" + 0.002*\"god\" + 0.001*\"don\" + 0.001*\"good\" + 0.001*\"think\" + 0.001*\"file\" + 0.001*\"gif\"\n",
      "2018-02-28 11:10:23,195 : INFO : topic #1 (0.167): 0.002*\"image\" + 0.002*\"edu\" + 0.002*\"don\" + 0.002*\"people\" + 0.001*\"graphics\" + 0.001*\"think\" + 0.001*\"just\" + 0.001*\"like\" + 0.001*\"data\" + 0.001*\"god\"\n",
      "2018-02-28 11:10:23,197 : INFO : topic #4 (0.167): 0.002*\"edu\" + 0.001*\"people\" + 0.001*\"don\" + 0.001*\"know\" + 0.001*\"image\" + 0.001*\"just\" + 0.001*\"time\" + 0.001*\"use\" + 0.001*\"graphics\" + 0.001*\"say\"\n",
      "2018-02-28 11:10:23,199 : INFO : topic #3 (0.167): 0.002*\"good\" + 0.002*\"think\" + 0.002*\"don\" + 0.002*\"year\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"know\" + 0.001*\"just\" + 0.001*\"argument\"\n",
      "2018-02-28 11:10:23,201 : INFO : topic #0 (0.167): 0.002*\"graphics\" + 0.002*\"don\" + 0.001*\"time\" + 0.001*\"know\" + 0.001*\"does\" + 0.001*\"like\" + 0.001*\"just\" + 0.001*\"jesus\" + 0.001*\"think\" + 0.001*\"good\"\n",
      "2018-02-28 11:10:23,203 : INFO : topic diff=0.979017, rho=0.577350\n",
      "2018-02-28 11:10:27,178 : INFO : -11.317 per-word bound, 2551.1 perplexity estimate based on a held-out corpus of 1661 documents with 241616 words\n",
      "2018-02-28 11:10:27,179 : INFO : PROGRESS: pass 2, at document #1661/1661\n",
      "2018-02-28 11:10:29,390 : INFO : topic #1 (0.167): 0.003*\"image\" + 0.002*\"edu\" + 0.002*\"don\" + 0.002*\"graphics\" + 0.002*\"people\" + 0.001*\"data\" + 0.001*\"pub\" + 0.001*\"like\" + 0.001*\"ftp\" + 0.001*\"just\"\n",
      "2018-02-28 11:10:29,392 : INFO : topic #3 (0.167): 0.002*\"good\" + 0.002*\"think\" + 0.002*\"year\" + 0.002*\"don\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"know\" + 0.001*\"argument\" + 0.001*\"just\"\n",
      "2018-02-28 11:10:29,394 : INFO : topic #5 (0.167): 0.003*\"jpeg\" + 0.002*\"image\" + 0.002*\"year\" + 0.002*\"does\" + 0.002*\"don\" + 0.002*\"gif\" + 0.002*\"good\" + 0.001*\"god\" + 0.001*\"file\" + 0.001*\"think\"\n",
      "2018-02-28 11:10:29,396 : INFO : topic #4 (0.167): 0.002*\"people\" + 0.001*\"don\" + 0.001*\"edu\" + 0.001*\"know\" + 0.001*\"just\" + 0.001*\"time\" + 0.001*\"image\" + 0.001*\"say\" + 0.001*\"like\" + 0.001*\"use\"\n",
      "2018-02-28 11:10:29,398 : INFO : topic #0 (0.167): 0.002*\"jesus\" + 0.002*\"graphics\" + 0.001*\"don\" + 0.001*\"time\" + 0.001*\"know\" + 0.001*\"does\" + 0.001*\"like\" + 0.001*\"just\" + 0.001*\"think\" + 0.001*\"matthew\"\n",
      "2018-02-28 11:10:29,400 : INFO : topic diff=0.564140, rho=0.500000\n",
      "2018-02-28 11:10:33,834 : INFO : -11.137 per-word bound, 2252.6 perplexity estimate based on a held-out corpus of 1661 documents with 241616 words\n",
      "2018-02-28 11:10:33,835 : INFO : PROGRESS: pass 3, at document #1661/1661\n",
      "2018-02-28 11:10:36,170 : INFO : topic #2 (0.167): 0.002*\"don\" + 0.002*\"just\" + 0.002*\"like\" + 0.002*\"know\" + 0.002*\"think\" + 0.002*\"people\" + 0.002*\"god\" + 0.001*\"time\" + 0.001*\"does\" + 0.001*\"good\"\n",
      "2018-02-28 11:10:36,172 : INFO : topic #3 (0.167): 0.002*\"good\" + 0.002*\"think\" + 0.002*\"year\" + 0.002*\"don\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"know\" + 0.001*\"argument\" + 0.001*\"just\"\n",
      "2018-02-28 11:10:36,174 : INFO : topic #5 (0.167): 0.003*\"jpeg\" + 0.002*\"image\" + 0.002*\"year\" + 0.002*\"gif\" + 0.002*\"don\" + 0.002*\"does\" + 0.002*\"file\" + 0.002*\"good\" + 0.001*\"god\" + 0.001*\"think\"\n",
      "2018-02-28 11:10:36,176 : INFO : topic #4 (0.167): 0.002*\"people\" + 0.001*\"don\" + 0.001*\"know\" + 0.001*\"just\" + 0.001*\"edu\" + 0.001*\"time\" + 0.001*\"say\" + 0.001*\"image\" + 0.001*\"like\" + 0.001*\"use\"\n",
      "2018-02-28 11:10:36,178 : INFO : topic #0 (0.167): 0.002*\"jesus\" + 0.002*\"graphics\" + 0.001*\"time\" + 0.001*\"don\" + 0.001*\"know\" + 0.001*\"like\" + 0.001*\"just\" + 0.001*\"does\" + 0.001*\"think\" + 0.001*\"matthew\"\n",
      "2018-02-28 11:10:36,180 : INFO : topic diff=0.328009, rho=0.447214\n",
      "2018-02-28 11:10:40,827 : INFO : -11.079 per-word bound, 2163.5 perplexity estimate based on a held-out corpus of 1661 documents with 241616 words\n",
      "2018-02-28 11:10:40,828 : INFO : PROGRESS: pass 4, at document #1661/1661\n",
      "2018-02-28 11:10:43,256 : INFO : topic #2 (0.167): 0.002*\"don\" + 0.002*\"just\" + 0.002*\"know\" + 0.002*\"think\" + 0.002*\"like\" + 0.002*\"people\" + 0.002*\"god\" + 0.001*\"time\" + 0.001*\"does\" + 0.001*\"good\"\n",
      "2018-02-28 11:10:43,258 : INFO : topic #1 (0.167): 0.003*\"image\" + 0.003*\"edu\" + 0.002*\"graphics\" + 0.002*\"don\" + 0.002*\"data\" + 0.001*\"people\" + 0.001*\"pub\" + 0.001*\"ftp\" + 0.001*\"like\" + 0.001*\"just\"\n",
      "2018-02-28 11:10:43,260 : INFO : topic #0 (0.167): 0.002*\"jesus\" + 0.002*\"graphics\" + 0.001*\"don\" + 0.001*\"time\" + 0.001*\"know\" + 0.001*\"just\" + 0.001*\"like\" + 0.001*\"does\" + 0.001*\"think\" + 0.001*\"matthew\"\n",
      "2018-02-28 11:10:43,263 : INFO : topic #3 (0.167): 0.002*\"good\" + 0.002*\"think\" + 0.002*\"year\" + 0.002*\"don\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"know\" + 0.001*\"argument\" + 0.001*\"just\"\n",
      "2018-02-28 11:10:43,265 : INFO : topic #4 (0.167): 0.002*\"people\" + 0.001*\"don\" + 0.001*\"know\" + 0.001*\"just\" + 0.001*\"time\" + 0.001*\"edu\" + 0.001*\"say\" + 0.001*\"like\" + 0.001*\"image\" + 0.001*\"use\"\n",
      "2018-02-28 11:10:43,267 : INFO : topic diff=0.196928, rho=0.408248\n",
      "2018-02-28 11:10:48,156 : INFO : -11.056 per-word bound, 2129.4 perplexity estimate based on a held-out corpus of 1661 documents with 241616 words\n",
      "2018-02-28 11:10:48,157 : INFO : PROGRESS: pass 5, at document #1661/1661\n",
      "2018-02-28 11:10:50,460 : INFO : topic #5 (0.167): 0.004*\"jpeg\" + 0.002*\"image\" + 0.002*\"year\" + 0.002*\"gif\" + 0.002*\"don\" + 0.002*\"file\" + 0.002*\"does\" + 0.002*\"good\" + 0.001*\"god\" + 0.001*\"won\"\n",
      "2018-02-28 11:10:50,462 : INFO : topic #0 (0.167): 0.002*\"jesus\" + 0.002*\"graphics\" + 0.001*\"don\" + 0.001*\"time\" + 0.001*\"know\" + 0.001*\"just\" + 0.001*\"like\" + 0.001*\"think\" + 0.001*\"matthew\" + 0.001*\"does\"\n",
      "2018-02-28 11:10:50,464 : INFO : topic #3 (0.167): 0.002*\"good\" + 0.002*\"year\" + 0.002*\"think\" + 0.002*\"don\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"know\" + 0.001*\"argument\" + 0.001*\"just\"\n",
      "2018-02-28 11:10:50,467 : INFO : topic #4 (0.167): 0.002*\"people\" + 0.001*\"don\" + 0.001*\"know\" + 0.001*\"just\" + 0.001*\"time\" + 0.001*\"edu\" + 0.001*\"say\" + 0.001*\"like\" + 0.001*\"image\" + 0.001*\"use\"\n",
      "2018-02-28 11:10:50,469 : INFO : topic #2 (0.167): 0.002*\"don\" + 0.002*\"just\" + 0.002*\"think\" + 0.002*\"know\" + 0.002*\"like\" + 0.002*\"people\" + 0.002*\"god\" + 0.001*\"time\" + 0.001*\"does\" + 0.001*\"good\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-28 11:10:50,471 : INFO : topic diff=0.121399, rho=0.377964\n",
      "2018-02-28 11:10:55,155 : INFO : -11.046 per-word bound, 2114.4 perplexity estimate based on a held-out corpus of 1661 documents with 241616 words\n",
      "2018-02-28 11:10:55,156 : INFO : PROGRESS: pass 6, at document #1661/1661\n",
      "2018-02-28 11:10:57,626 : INFO : topic #0 (0.167): 0.002*\"jesus\" + 0.002*\"graphics\" + 0.001*\"don\" + 0.001*\"time\" + 0.001*\"know\" + 0.001*\"just\" + 0.001*\"matthew\" + 0.001*\"like\" + 0.001*\"think\" + 0.001*\"does\"\n",
      "2018-02-28 11:10:57,628 : INFO : topic #1 (0.167): 0.003*\"image\" + 0.003*\"edu\" + 0.002*\"graphics\" + 0.002*\"don\" + 0.002*\"data\" + 0.002*\"pub\" + 0.001*\"ftp\" + 0.001*\"people\" + 0.001*\"like\" + 0.001*\"atheists\"\n",
      "2018-02-28 11:10:57,630 : INFO : topic #5 (0.167): 0.004*\"jpeg\" + 0.002*\"image\" + 0.002*\"year\" + 0.002*\"gif\" + 0.002*\"don\" + 0.002*\"file\" + 0.002*\"does\" + 0.002*\"good\" + 0.001*\"god\" + 0.001*\"won\"\n",
      "2018-02-28 11:10:57,632 : INFO : topic #3 (0.167): 0.002*\"good\" + 0.002*\"year\" + 0.002*\"think\" + 0.002*\"don\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"argument\" + 0.001*\"know\" + 0.001*\"just\"\n",
      "2018-02-28 11:10:57,635 : INFO : topic #4 (0.167): 0.002*\"people\" + 0.001*\"don\" + 0.001*\"just\" + 0.001*\"know\" + 0.001*\"time\" + 0.001*\"edu\" + 0.001*\"say\" + 0.001*\"like\" + 0.001*\"image\" + 0.001*\"think\"\n",
      "2018-02-28 11:10:57,637 : INFO : topic diff=0.076904, rho=0.353553\n",
      "2018-02-28 11:11:02,403 : INFO : -11.041 per-word bound, 2106.9 perplexity estimate based on a held-out corpus of 1661 documents with 241616 words\n",
      "2018-02-28 11:11:02,403 : INFO : PROGRESS: pass 7, at document #1661/1661\n",
      "2018-02-28 11:11:04,770 : INFO : topic #1 (0.167): 0.003*\"image\" + 0.003*\"edu\" + 0.002*\"graphics\" + 0.002*\"don\" + 0.002*\"data\" + 0.002*\"pub\" + 0.002*\"ftp\" + 0.001*\"people\" + 0.001*\"like\" + 0.001*\"atheists\"\n",
      "2018-02-28 11:11:04,772 : INFO : topic #3 (0.167): 0.002*\"good\" + 0.002*\"year\" + 0.002*\"think\" + 0.002*\"don\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"argument\" + 0.001*\"know\" + 0.001*\"just\"\n",
      "2018-02-28 11:11:04,775 : INFO : topic #4 (0.167): 0.002*\"people\" + 0.001*\"don\" + 0.001*\"just\" + 0.001*\"know\" + 0.001*\"time\" + 0.001*\"edu\" + 0.001*\"say\" + 0.001*\"like\" + 0.001*\"think\" + 0.001*\"image\"\n",
      "2018-02-28 11:11:04,777 : INFO : topic #2 (0.167): 0.002*\"don\" + 0.002*\"just\" + 0.002*\"think\" + 0.002*\"know\" + 0.002*\"people\" + 0.002*\"like\" + 0.002*\"god\" + 0.001*\"time\" + 0.001*\"does\" + 0.001*\"good\"\n",
      "2018-02-28 11:11:04,779 : INFO : topic #5 (0.167): 0.004*\"jpeg\" + 0.002*\"image\" + 0.002*\"year\" + 0.002*\"gif\" + 0.002*\"don\" + 0.002*\"file\" + 0.002*\"does\" + 0.002*\"good\" + 0.001*\"god\" + 0.001*\"won\"\n",
      "2018-02-28 11:11:04,781 : INFO : topic diff=0.050026, rho=0.333333\n",
      "2018-02-28 11:11:09,852 : INFO : -11.038 per-word bound, 2102.7 perplexity estimate based on a held-out corpus of 1661 documents with 241616 words\n",
      "2018-02-28 11:11:09,852 : INFO : PROGRESS: pass 8, at document #1661/1661\n",
      "2018-02-28 11:11:12,265 : INFO : topic #2 (0.167): 0.002*\"don\" + 0.002*\"just\" + 0.002*\"think\" + 0.002*\"know\" + 0.002*\"people\" + 0.002*\"like\" + 0.002*\"god\" + 0.001*\"time\" + 0.001*\"does\" + 0.001*\"good\"\n",
      "2018-02-28 11:11:12,268 : INFO : topic #3 (0.167): 0.002*\"good\" + 0.002*\"year\" + 0.002*\"think\" + 0.002*\"don\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"argument\" + 0.001*\"know\" + 0.001*\"just\"\n",
      "2018-02-28 11:11:12,269 : INFO : topic #5 (0.167): 0.004*\"jpeg\" + 0.002*\"image\" + 0.002*\"year\" + 0.002*\"gif\" + 0.002*\"don\" + 0.002*\"file\" + 0.002*\"does\" + 0.002*\"good\" + 0.001*\"god\" + 0.001*\"won\"\n",
      "2018-02-28 11:11:12,272 : INFO : topic #4 (0.167): 0.002*\"people\" + 0.001*\"don\" + 0.001*\"just\" + 0.001*\"know\" + 0.001*\"time\" + 0.001*\"edu\" + 0.001*\"say\" + 0.001*\"like\" + 0.001*\"think\" + 0.001*\"use\"\n",
      "2018-02-28 11:11:12,274 : INFO : topic #1 (0.167): 0.003*\"image\" + 0.003*\"edu\" + 0.002*\"graphics\" + 0.002*\"don\" + 0.002*\"data\" + 0.002*\"pub\" + 0.002*\"ftp\" + 0.001*\"people\" + 0.001*\"like\" + 0.001*\"atheists\"\n",
      "2018-02-28 11:11:12,277 : INFO : topic diff=0.033343, rho=0.316228\n",
      "2018-02-28 11:11:17,247 : INFO : -11.036 per-word bound, 2100.0 perplexity estimate based on a held-out corpus of 1661 documents with 241616 words\n",
      "2018-02-28 11:11:17,248 : INFO : PROGRESS: pass 9, at document #1661/1661\n",
      "2018-02-28 11:11:19,493 : INFO : topic #1 (0.167): 0.003*\"image\" + 0.003*\"edu\" + 0.002*\"graphics\" + 0.002*\"data\" + 0.002*\"don\" + 0.002*\"pub\" + 0.002*\"ftp\" + 0.001*\"people\" + 0.001*\"like\" + 0.001*\"mail\"\n",
      "2018-02-28 11:11:19,495 : INFO : topic #4 (0.167): 0.002*\"people\" + 0.001*\"don\" + 0.001*\"just\" + 0.001*\"know\" + 0.001*\"time\" + 0.001*\"edu\" + 0.001*\"say\" + 0.001*\"like\" + 0.001*\"think\" + 0.001*\"use\"\n",
      "2018-02-28 11:11:19,497 : INFO : topic #3 (0.167): 0.002*\"good\" + 0.002*\"year\" + 0.002*\"think\" + 0.002*\"don\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"argument\" + 0.001*\"know\" + 0.001*\"just\"\n",
      "2018-02-28 11:11:19,499 : INFO : topic #0 (0.167): 0.002*\"jesus\" + 0.002*\"graphics\" + 0.001*\"don\" + 0.001*\"time\" + 0.001*\"know\" + 0.001*\"matthew\" + 0.001*\"think\" + 0.001*\"just\" + 0.001*\"like\" + 0.001*\"does\"\n",
      "2018-02-28 11:11:19,501 : INFO : topic #2 (0.167): 0.002*\"don\" + 0.002*\"just\" + 0.002*\"think\" + 0.002*\"know\" + 0.002*\"people\" + 0.002*\"like\" + 0.002*\"god\" + 0.001*\"time\" + 0.001*\"does\" + 0.001*\"good\"\n",
      "2018-02-28 11:11:19,504 : INFO : topic diff=0.022722, rho=0.301511\n"
     ]
    }
   ],
   "source": [
    "# Create lda model (equivalent to \"fit\" in sklearn)\n",
    "lda = models.LdaModel(corpus=corpus, num_topics=6, id2word=id2word, passes=10, minimum_probability=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Let's take a look at what happened.  Here are the 5 most important words for each of the 3 topics we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-28 11:11:59,685 : INFO : topic #0 (0.167): 0.002*\"jesus\" + 0.002*\"graphics\" + 0.001*\"don\" + 0.001*\"time\" + 0.001*\"know\" + 0.001*\"matthew\" + 0.001*\"think\" + 0.001*\"just\" + 0.001*\"like\" + 0.001*\"does\"\n",
      "2018-02-28 11:11:59,687 : INFO : topic #1 (0.167): 0.003*\"image\" + 0.003*\"edu\" + 0.002*\"graphics\" + 0.002*\"data\" + 0.002*\"don\" + 0.002*\"pub\" + 0.002*\"ftp\" + 0.001*\"people\" + 0.001*\"like\" + 0.001*\"mail\"\n",
      "2018-02-28 11:11:59,690 : INFO : topic #2 (0.167): 0.002*\"don\" + 0.002*\"just\" + 0.002*\"think\" + 0.002*\"know\" + 0.002*\"people\" + 0.002*\"like\" + 0.002*\"god\" + 0.001*\"time\" + 0.001*\"does\" + 0.001*\"good\"\n",
      "2018-02-28 11:11:59,692 : INFO : topic #3 (0.167): 0.002*\"good\" + 0.002*\"year\" + 0.002*\"think\" + 0.002*\"don\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"argument\" + 0.001*\"know\" + 0.001*\"just\"\n",
      "2018-02-28 11:11:59,694 : INFO : topic #4 (0.167): 0.002*\"people\" + 0.001*\"don\" + 0.001*\"just\" + 0.001*\"know\" + 0.001*\"time\" + 0.001*\"edu\" + 0.001*\"say\" + 0.001*\"like\" + 0.001*\"think\" + 0.001*\"use\"\n",
      "2018-02-28 11:11:59,696 : INFO : topic #5 (0.167): 0.004*\"jpeg\" + 0.002*\"image\" + 0.002*\"year\" + 0.002*\"gif\" + 0.002*\"don\" + 0.002*\"file\" + 0.002*\"does\" + 0.002*\"good\" + 0.001*\"god\" + 0.001*\"won\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.002*\"jesus\" + 0.002*\"graphics\" + 0.001*\"don\" + 0.001*\"time\" + 0.001*\"know\" + 0.001*\"matthew\" + 0.001*\"think\" + 0.001*\"just\" + 0.001*\"like\" + 0.001*\"does\"'),\n",
       " (1,\n",
       "  '0.003*\"image\" + 0.003*\"edu\" + 0.002*\"graphics\" + 0.002*\"data\" + 0.002*\"don\" + 0.002*\"pub\" + 0.002*\"ftp\" + 0.001*\"people\" + 0.001*\"like\" + 0.001*\"mail\"'),\n",
       " (2,\n",
       "  '0.002*\"don\" + 0.002*\"just\" + 0.002*\"think\" + 0.002*\"know\" + 0.002*\"people\" + 0.002*\"like\" + 0.002*\"god\" + 0.001*\"time\" + 0.001*\"does\" + 0.001*\"good\"'),\n",
       " (3,\n",
       "  '0.002*\"good\" + 0.002*\"year\" + 0.002*\"think\" + 0.002*\"don\" + 0.002*\"does\" + 0.001*\"like\" + 0.001*\"god\" + 0.001*\"argument\" + 0.001*\"know\" + 0.001*\"just\"'),\n",
       " (4,\n",
       "  '0.002*\"people\" + 0.001*\"don\" + 0.001*\"just\" + 0.001*\"know\" + 0.001*\"time\" + 0.001*\"edu\" + 0.001*\"say\" + 0.001*\"like\" + 0.001*\"think\" + 0.001*\"use\"'),\n",
       " (5,\n",
       "  '0.004*\"jpeg\" + 0.002*\"image\" + 0.002*\"year\" + 0.002*\"gif\" + 0.002*\"don\" + 0.002*\"file\" + 0.002*\"does\" + 0.002*\"good\" + 0.001*\"god\" + 0.001*\"won\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Topic Space\n",
    "If we want to map our documents to the topic space we need to actually use the LdaModel transformer that we created above, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x1a194ed198>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the docs from the word space to the topic space (like \"transform\" in sklearn)\n",
    "lda_corpus = lda[corpus]\n",
    "lda_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Store the documents' topic vectors in a list so we can take a peak\n",
    "lda_docs = [doc for doc in lda_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Now we can take a look at the document vectors in the topic space, which are measures of the component of each document along each topic.  Thus, at most a document vector can have num_topics=3 nonzero components in the topic space, and most have far fewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.9927336384858032)],\n",
       " [(2, 0.982152467234927)],\n",
       " [(0, 0.76219679209689462), (1, 0.23112987593817744)],\n",
       " [(0, 0.021284637174004715),\n",
       "  (1, 0.1418771963330436),\n",
       "  (2, 0.83683816649295162)],\n",
       " [(2, 0.98749660660566974)],\n",
       " [(1, 0.99245586302368782)],\n",
       " [(0, 0.99337251384713232)],\n",
       " [(0, 0.012659039402200072),\n",
       "  (1, 0.97581570966376718),\n",
       "  (2, 0.011525250934032824)],\n",
       " [(0, 0.017283551295813198),\n",
       "  (1, 0.96479380172954432),\n",
       "  (2, 0.017922646974642506)],\n",
       " [(1, 0.98948203339383223)],\n",
       " [(0, 0.98275808620714067)],\n",
       " [(0, 0.98397097980191628)],\n",
       " [(0, 0.024810731111041293),\n",
       "  (1, 0.025285634903234773),\n",
       "  (2, 0.94990363398572397)],\n",
       " [(1, 0.99283808119602535)],\n",
       " [(0, 0.99292617530340865)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the document vectors in the topic space for the first 5 documents\n",
    "lda_docs[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nStone, DeRose: Geometric characterization of parametric cubic curves.\\nACM Trans. Graphics 8 (3) (1989) 147 - 163.\\n\\n\\nManocha, Canny: Detecting cusps and inflection points in curves.\\nComputer aided geometric design 9 (1992) 1-24.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_train.data[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LdaModel.log_perplexity of <gensim.models.ldamodel.LdaModel object at 0x10f5c0ad0>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.log_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## On your own...\n",
    "- Go get some of the NIPS papers from [here](https://archive.ics.uci.edu/ml/datasets/Bag+of+Words).  \n",
    "- Try performing LDA on this data with gensim\n",
    "- Play with some of the preprocessing options and parameters for LDA, observe what happens\n",
    "- See if you can use the resulting topic space to extract topic vectors and cluster some documents\n",
    "- How do your results look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "123px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
